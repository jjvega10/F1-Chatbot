{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ca36e7a",
   "metadata": {},
   "source": [
    "# Tool Call Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1658856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model response requesting tool call:\n",
      "\n",
      "ChatCompletion(id='chatcmpl-ijy69c2j37j9mngd0274a', choices=[Choice(finish_reason='tool_calls', index=0, logprobs=None, message=ChatCompletionMessage(content='', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=[ChatCompletionMessageFunctionToolCall(id='478634966', function=Function(arguments='{\"order_id\":\"1017\"}', name='get_delivery_date'), type='function')]))], created=1757079674, model='qwen/qwen3-4b-2507', object='chat.completion', service_tier=None, system_fingerprint='qwen/qwen3-4b-2507', usage=CompletionUsage(completion_tokens=25, prompt_tokens=223, total_tokens=248, completion_tokens_details=None, prompt_tokens_details=None), stats={})\n",
      "\n",
      "get_delivery_date function returns delivery date: \n",
      "\n",
      "2025-09-12 07:41:15.031488\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "import random\n",
    "from openai import OpenAI\n",
    "\n",
    "# Point to the local server\n",
    "client = OpenAI(base_url=\"http://localhost:1234/v1\", api_key=\"lm-studio\")\n",
    "model = \"qwen/qwen3-4b-2507\"\n",
    "\n",
    "def get_delivery_date(order_id:str):\n",
    "    \"\"\"Generate a random delivery date between today and 14 days from now\n",
    "    In a real-world scenario, this function would query a database or API\"\"\"\n",
    "    today = datetime.now()\n",
    "    random_days = random.randint(1, 14)\n",
    "    delivery_date = today + timedelta(days=random_days)\n",
    "    print(f\"\\nget_delivery_date function returns delivery date: \\n\\n{delivery_date}\",\n",
    "          flush=True)\n",
    "    return delivery_date\n",
    "\n",
    "tools = [\n",
    "    {\n",
    "        \"type\":\"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_delivery_date\",\n",
    "            \"description\": \"Get the delivery date for a customer's order. Call this whenever you need to know the delivery date, for example when a customer asks 'Where is my package'\",\n",
    "            \"parameters\":  {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"order_id\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The customer's order ID.\",\n",
    "                    },\n",
    "                },\n",
    "                \"required\":[\"order_id\"],\n",
    "                \"additionalProperties\": False,\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "]\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\":\"system\",\n",
    "        \"content\":\"You are a helpful customer support assistant. Use the supplied tools to assist the user.\",\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Give me the delivery date and time for order number 1017\",\n",
    "    },\n",
    "]\n",
    "\n",
    "# LM Studio\n",
    "response = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=messages,\n",
    "    tools=tools,\n",
    ")\n",
    "\n",
    "print('\\nModel response requesting tool call:\\n', flush=True)\n",
    "print(response, flush=True)\n",
    "\n",
    "# Extract the arguments for get_delivery_date\n",
    "# Note this code assumes we have already determined that the model generated a function call.\n",
    "tool_call = response.choices[0].message.tool_calls[0]\n",
    "arguments = json.loads(tool_call.function.arguments)\n",
    "\n",
    "order_id = arguments.get(\"order_id\")\n",
    "\n",
    "# Call the get_delivery_date function with the extracted order_id\n",
    "delivery_date = get_delivery_date(order_id)\n",
    "\n",
    "assistant_tool_call_request_message = {\n",
    "    \"role\": \"assistant\",\n",
    "    \"tool_calls\": [\n",
    "        {\n",
    "            \"id\":response.choices[0].message.tool_calls[0].id,\n",
    "            \"type\":response.choices[0].message.tool_calls[0].type,\n",
    "            \"function\":response.choices[0].message.tool_calls[0].function,\n",
    "        }\n",
    "    ],\n",
    "}\n",
    "\n",
    "# Create a message containing the result of the function call\n",
    "function_call_result_message = {\n",
    "    \"role\":\"tool\",\n",
    "    \"content\": json.dumps(\n",
    "        {\n",
    "            \"order_id\": order_id,\n",
    "            \"delivery_date\": delivery_date.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        }\n",
    "    ),\n",
    "    \"tool_call_id\": response.choices[0].message.tool_calls[0].id,\n",
    "}\n",
    "\n",
    "# Prepare the chat completion call payload\n",
    "completion_messages_payload = [\n",
    "    messages[0],\n",
    "    messages[1],\n",
    "    assistant_tool_call_request_message,\n",
    "    function_call_result_message,\n",
    "]\n",
    "\n",
    "# Call the OpenAI API's chat completions endpoint to send the tool call result back\n",
    "# to the model\n",
    "response = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=completion_messages_payload,\n",
    ")\n",
    "\n",
    "print(\"\\nFinal model response with knowledge of the tool call result:\\n\")\n",
    "print(response.choices[0].message.content, flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a663736f",
   "metadata": {},
   "source": [
    "# F1 Tool Calls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07078b76",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3f3d0a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_f1_driver_standings(standings_type:str)->str:\n",
    "    \"\"\"Get F1 2025 driver standings.\"\"\"\n",
    "    if standings_type==\"team\":\n",
    "        url = f\"https://www.formula1.com/en/results/2025/team\"\n",
    "    else:\n",
    "        url = f\"https://www.formula1.com/en/results/2025/drivers\"\n",
    "    soup_og = extract_text_from_dynamic_site(url, wait_time=3)\n",
    "    html_table = soup_og.find_all('table')[0]\n",
    "    html_text = str(html_table.prettify())\n",
    "    html_text = re.sub(\" class=\\\"[^\\\"]*\\\"\", \"\", html_text)\n",
    "    html_text = re.sub(\"<img[^>]*>\", \"\", html_text)\n",
    "    html_text = re.sub(\"<a[^>]*>\", \"\", html_text)\n",
    "    html_text = re.sub(\"<span[^>]*>\", \"\", html_text)\n",
    "    html_text = re.sub(\"</span[^>]*>\", \"\", html_text)\n",
    "    html_text = re.sub(\"<br>\", \"\", html_text)\n",
    "    html_text = re.sub(\"<p>\", \"\", html_text)\n",
    "    html_text = re.sub(\"\\\\\\n *\", \"\", html_text)\n",
    "    drivers_standings_table = htmltabletomd.convert_table(html_text)\n",
    "    return drivers_standings_table\n",
    "\n",
    "def get_f1_team_standings():\n",
    "    \"\"\"Get F1 2025 team standings.\"\"\"\n",
    "    url = f\"https://www.formula1.com/en/results/2025/team\"\n",
    "    soup_og = extract_text_from_dynamic_site(url, wait_time=3)\n",
    "    html_table = soup_og.find_all('table')[0]\n",
    "    html_text = str(html_table.prettify())\n",
    "    html_text = re.sub(\" class=\\\"[^\\\"]*\\\"\", \"\", html_text)\n",
    "    html_text = re.sub(\"<img[^>]*>\", \"\", html_text)\n",
    "    html_text = re.sub(\"<a[^>]*>\", \"\", html_text)\n",
    "    html_text = re.sub(\"<span[^>]*>\", \"\", html_text)\n",
    "    html_text = re.sub(\"</span[^>]*>\", \"\", html_text)\n",
    "    html_text = re.sub(\"<br>\", \"\", html_text)\n",
    "    html_text = re.sub(\"<p>\", \"\", html_text)\n",
    "    html_text = re.sub(\"\\\\\\n *\", \"\", html_text)\n",
    "    standings_table = htmltabletomd.convert_table(html_text)\n",
    "    return standings_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "23e58598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: https://www.formula1.com/en/results/2025/drivers\n"
     ]
    }
   ],
   "source": [
    "tbl = get_f1_driver_standings('drivers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e5905967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model response requesting tool call:\n",
      "\n",
      "ChatCompletion(id='chatcmpl-dmni5wo1ty9updbcwkusaj', choices=[Choice(finish_reason='tool_calls', index=0, logprobs=None, message=ChatCompletionMessage(content='', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=[ChatCompletionMessageFunctionToolCall(id='549168276', function=Function(arguments='{\"standings_type\":\"drivers\"}', name='get_f1_standings'), type='function')]))], created=1757082163, model='qwen/qwen3-4b-2507', object='chat.completion', service_tier=None, system_fingerprint='qwen/qwen3-4b-2507', usage=CompletionUsage(completion_tokens=25, prompt_tokens=229, total_tokens=254, completion_tokens_details=None, prompt_tokens_details=None), stats={})\n",
      "Loaded: https://www.formula1.com/en/results/2025/drivers\n",
      "\n",
      "Final model response with knowledge of the tool call result:\n",
      "\n",
      "The driver who is NOT part of Red Bull, Mercedes, Ferrari, or McLaren and has the most points is **Alexander Albon** from Williams, with **64 points**. \n",
      "\n",
      "Note: Although Albon is from Williams, which is not one of the four teams mentioned (Red Bull, Mercedes, Ferrari, or McLaren), the query asks for a driver not part of those four teams. Therefore, Albon qualifies. \n",
      "\n",
      "However, Kimi Antonelli from Mercedes also has 64 points, but he is part of Mercedes, so he does not meet the criteria.\n",
      "\n",
      "Thus, the correct answer is **Alexander Albon** with 64 points. ✅\n"
     ]
    }
   ],
   "source": [
    "# Point to the local server\n",
    "client = OpenAI(base_url=\"http://localhost:1234/v1\", api_key=\"lm-studio\")\n",
    "model = \"qwen/qwen3-4b-2507\"\n",
    "\n",
    "tools = [\n",
    "    {\n",
    "        \"type\":\"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_f1_standings\",\n",
    "            \"description\": \"Get the current F1 drivers standings. Use it to determine the points for each driver in the driver's championship.\",\n",
    "            \"parameters\":  {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"standings_type\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Selects either 'drivers' or 'team' championship standings.\"\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "                \"required\":[\"standings_type\"],\n",
    "                \"additionalProperties\": False,\n",
    "            },\n",
    "        },\n",
    "]\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\":\"system\",\n",
    "        \"content\":\"You are an expert in Formula 1 that will assist the user with questions regarding the sport. Use the supplied tools to assist the user.\",\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Which driver who is NOT part of Red Bull, Mercedes, Ferrari or Mclaren has the most points?\",\n",
    "    },\n",
    "]\n",
    "\n",
    "# LM Studio\n",
    "response = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=messages,\n",
    "    tools=tools,\n",
    ")\n",
    "\n",
    "print('\\nModel response requesting tool call:\\n', flush=True)\n",
    "print(response, flush=True)\n",
    "\n",
    "# Extract the arguments for get_delivery_date\n",
    "# Note this code assumes we have already determined that the model generated a function call.\n",
    "tool_call = response.choices[0].message.tool_calls[0]\n",
    "arguments = json.loads(tool_call.function.arguments)\n",
    "\n",
    "standings_type = arguments.get(\"standings_type\")\n",
    "# Call the get_delivery_date function with the extracted order_id\n",
    "drivers_standings_table = get_f1_driver_standings(standings_type)\n",
    "\n",
    "assistant_tool_call_request_message = {\n",
    "    \"role\": \"assistant\",\n",
    "    \"tool_calls\": [\n",
    "        {\n",
    "            \"id\":response.choices[0].message.tool_calls[0].id,\n",
    "            \"type\":response.choices[0].message.tool_calls[0].type,\n",
    "            \"function\":response.choices[0].message.tool_calls[0].function,\n",
    "        }\n",
    "    ],\n",
    "}\n",
    "\n",
    "# Create a message containing the result of the function call\n",
    "function_call_result_message = {\n",
    "    \"role\":\"tool\",\n",
    "    \"content\": json.dumps(\n",
    "        {\n",
    "            \"standings_type\": standings_type,\n",
    "            \"drivers_standings_table\": drivers_standings_table,\n",
    "        }\n",
    "    ),\n",
    "    \"tool_call_id\": response.choices[0].message.tool_calls[0].id,\n",
    "}\n",
    "\n",
    "# Prepare the chat completion call payload\n",
    "completion_messages_payload = [\n",
    "    messages[0],\n",
    "    messages[1],\n",
    "    assistant_tool_call_request_message,\n",
    "    function_call_result_message,\n",
    "]\n",
    "\n",
    "# Call the OpenAI API's chat completions endpoint to send the tool call result back\n",
    "# to the model\n",
    "response = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=completion_messages_payload,\n",
    ")\n",
    "\n",
    "print(\"\\nFinal model response with knowledge of the tool call result:\\n\")\n",
    "print(response.choices[0].message.content, flush=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
