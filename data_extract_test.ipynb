{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c86ebc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import time\n",
    "import htmltabletomd\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from openai import OpenAI\n",
    "import json\n",
    "import pandas as pd\n",
    "import htmlmin\n",
    "from io import StringIO\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "def extract_text_from_dynamic_site(url, wait_time=10):\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--headless\")\n",
    "    chrome_options.add_argument(\"--no-sandbox\")\n",
    "    chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    chrome_options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "    chrome_options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "    chrome_options.add_experimental_option('useAutomationExtension', False)\n",
    "\n",
    "    service = Service(ChromeDriverManager().install())\n",
    "    driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        print(f\"Loaded: {url}\")\n",
    "        time.sleep(wait_time)\n",
    "        page_source = driver.page_source\n",
    "        soup = BeautifulSoup(page_source, 'html.parser')\n",
    "        return soup\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None\n",
    "    finally:\n",
    "        driver.quit()\n",
    "\n",
    "def get_f1_driver_standings(\n",
    "    standings_type: Annotated[str, \"Select 'drivers' or 'team' championship standings.\"]\n",
    ") -> str:\n",
    "    \"\"\"Get the current F1 drivers or teams standings. \n",
    "    Use it to determine the points for each driver in the driver's championship or the points for each team in the teams' championship.\"\"\"\n",
    "    if standings_type==\"team\":\n",
    "        url = f\"https://www.formula1.com/en/results/2025/team\"\n",
    "    else:\n",
    "        url = f\"https://www.formula1.com/en/results/2025/drivers\"\n",
    "    soup_og = extract_text_from_dynamic_site(url, wait_time=3)\n",
    "    html_table = soup_og.find_all('table')[0]\n",
    "    html_text = str(html_table.prettify())\n",
    "    html_text = re.sub(\" class=\\\"[^\\\"]*\\\"\", \"\", html_text)\n",
    "    html_text = re.sub(\"<img[^>]*>\", \"\", html_text)\n",
    "    html_text = re.sub(\"<a[^>]*>\", \"\", html_text)\n",
    "    html_text = re.sub(\"<span[^>]*>\", \"\", html_text)\n",
    "    html_text = re.sub(\"</span[^>]*>\", \"\", html_text)\n",
    "    html_text = re.sub(\"<br>\", \"\", html_text)\n",
    "    html_text = re.sub(\"<p>\", \"\", html_text)\n",
    "    html_text = re.sub(\"\\\\\\n *\", \"\", html_text)\n",
    "    drivers_standings_table = htmltabletomd.convert_table(html_text)\n",
    "    return drivers_standings_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe192fa3",
   "metadata": {},
   "source": [
    "# Extract Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ee833a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: https://www.formula1.com/en/racing/2025.html\n"
     ]
    }
   ],
   "source": [
    "url = f\"https://www.formula1.com/en/racing/2025.html\"\n",
    "soup_og = extract_text_from_dynamic_site(url, wait_time=3)\n",
    "def get_info(x):\n",
    "    x = x.prettify()\n",
    "    x = re.sub(\" class=\\\"[^\\\"]*\\\"\", \"\", x)\n",
    "    x = re.sub(\"<img[^>]*>\", \"\", x)\n",
    "    x = re.sub(\"<svg[^>]*>\", \"\", x)\n",
    "    x = re.sub(\"</svg[^>]*>\", \"\", x)\n",
    "    x = re.sub(\"<path[^>]*>\", \"\", x)\n",
    "    x = re.sub(\"</path[^>]*>\", \"\", x)\n",
    "    x = re.sub(\"<a[^>]*>\", \"\", x)\n",
    "    x = re.sub(\"<span[^>]*>\", \"<span>\", x)\n",
    "    x = re.sub(\"</span[^>]*>\", \"</span>\", x)\n",
    "    x = re.sub(\"<defs[^>]*>\", \"\", x)\n",
    "    x = re.sub(\"</defs[^>]*>\", \"\", x)\n",
    "    x = re.sub(\"<g[^>]*>\", \"\", x)\n",
    "    x = re.sub(\"</g[^>]*>\", \"\", x)\n",
    "    x = re.sub(\"<clippath[^>]*>\", \"\", x)\n",
    "    x = re.sub(\"</clippath[^>]*>\", \"\", x)\n",
    "    x = re.sub(\"<br>\", \"\", x)\n",
    "    x = re.sub(\"<p>\", \"\", x)\n",
    "    x = x.splitlines()\n",
    "    y = []\n",
    "    for line in x:\n",
    "        if line.strip() != \"\":\n",
    "            y.append(line.strip())\n",
    "    event_text = ''.join(y)\n",
    "    event_info = re.findall(r\"(?<=>)[^<>]+(?=<)\", event_text)\n",
    "    return event_info\n",
    "possible_races = soup_og.find_all(attrs={\"data-f1rd-a7s-click\": \"event_tile_click\"})\n",
    "race_cards = []\n",
    "for race in possible_races:\n",
    "    if len(race.find_all('title')) > 0:\n",
    "        race_cards.append(race)\n",
    "for race in race_cards:\n",
    "    country = race.find_all('title')[-1].text[8:]\n",
    "event_info_list = []\n",
    "for race in race_cards:\n",
    "    event_info_list.append(get_info(race))\n",
    "events = []\n",
    "event_dict = {}\n",
    "for event in event_info_list:\n",
    "    if len(event)==5:\n",
    "        round = event[0]\n",
    "        country = event[2]\n",
    "        event_name = event[3]\n",
    "        dates = event[4]\n",
    "    elif len(event)==6:\n",
    "        round = event[0]\n",
    "        country = event[3]\n",
    "        event_name = event[4]\n",
    "        dates = event[5]\n",
    "    if len(event)>6:\n",
    "        round = event[0]\n",
    "        country = event[4]\n",
    "        event_name = event[5]\n",
    "        dates = event[2]\n",
    "    event_dict[round] = {\"Country\": country, \"Dates\": dates}\n",
    "schedule_df = pd.DataFrame(event_dict).T\n",
    "schedule_text = schedule_df.to_markdown()\n",
    "# Write schedule_text to an txt file\n",
    "with open(\"data-cache/schedule_text.txt\", \"w\") as f:\n",
    "    f.write(schedule_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8b74d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_url = 'https://www.formula1.com'\n",
    "# event_links_soup = extract_text_from_dynamic_site(base_url+race_cards[-2]['href'], wait_time=1)\n",
    "# session_soup = extract_text_from_dynamic_site(base_url+event_links_soup.find_all('a', string='Results')[-1]['href'], wait_time=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5283d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract timesheet (aprox 3 min.)\n",
    "if os.path.exists('data-cache/2025_timesheet.pqt'):\n",
    "    timesheet_df = pd.read_parquet('data-cache/2025_timesheet.pqt')\n",
    "else:\n",
    "    base_url = 'https://www.formula1.com'\n",
    "    timesheet_dfs = []\n",
    "    for race in race_cards[1:]:\n",
    "        event_url = base_url+race['href']\n",
    "        url_name = event_url.split('/')[-1]\n",
    "        year = event_url.split('/')[-2]\n",
    "        event_links_soup = extract_text_from_dynamic_site(base_url+race['href'], wait_time=1)\n",
    "        sessions_dict = {}\n",
    "        if len(event_links_soup.find_all('a', string='Results'))==0:\n",
    "            sessions_iter = event_links_soup.find_all('time')[0].parent.parent.parent.parent.children\n",
    "            future_event = True\n",
    "        else:\n",
    "            sessions_iter = event_links_soup.find_all('time')[0].parent.parent.parent.parent.parent.children\n",
    "            future_event = False\n",
    "        for session in sessions_iter:\n",
    "            spans = []\n",
    "            for span in session.find_all('span'):\n",
    "                if len(span.find_all())==0:\n",
    "                    spans.append(span.text)\n",
    "            times = []\n",
    "            for time_list in session.find_all('time'):\n",
    "                times.append(time_list.text)\n",
    "            if len(times)==0 and len(spans)==0:\n",
    "                continue\n",
    "            if future_event:\n",
    "                session_name = spans[-2]\n",
    "            else:\n",
    "                session_name = spans[-1]\n",
    "            if len(times)==2:\n",
    "                sessions_dict[session_name] = {'RACE':url_name, \n",
    "                                            'DATE': f\"{spans[1]} {spans[0]}, {year}\",\n",
    "                                            'START_HOUR':times[0],\n",
    "                                            'END_HOUR':times[1]}\n",
    "            elif len(times)==1:\n",
    "                sessions_dict[session_name] = {'RACE':url_name, \n",
    "                                            'DATE': f\"{spans[1]} {spans[0]}, {year}\",\n",
    "                                            'START_HOUR':times[0]}\n",
    "        session_timesheet = pd.DataFrame(sessions_dict).T.reset_index().rename({'index':'SESSION'}, axis=1)\n",
    "        session_timesheet['YEAR'] = year\n",
    "        timesheet_dfs.append(session_timesheet)\n",
    "    timesheet_df = pd.concat(timesheet_dfs).reset_index(drop=True)\n",
    "    timesheet_df = timesheet_df[['YEAR', 'RACE', 'SESSION', 'DATE', 'START_HOUR', 'END_HOUR']]\n",
    "    timesheet_df['START_TIME'] = pd.to_datetime(timesheet_df['DATE']+' '+timesheet_df['START_HOUR'])\n",
    "    timesheet_df['END_TIME'] = pd.to_datetime(np.where(timesheet_df['END_HOUR'].notna(), (timesheet_df['DATE']+' '+timesheet_df['END_HOUR']), pd.NaT))\n",
    "    timesheet_df.to_parquet('data-cache/2025_timesheet.pqt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c182b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tz_timedelta = pd.Timestamp('now').tz_localize('utc') - pd.Timestamp('now', tz='utc')\n",
    "f1_2025_last_update = pd.to_datetime(os.path.getmtime('data-cache/f1_2025.pqt'), unit='s')\n",
    "f1_2025_last_update = f1_2025_last_update + tz_timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3de6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract results (aprox 12 min.)\n",
    "base_url = 'https://www.formula1.com'\n",
    "dfs = []\n",
    "refresh_all = False\n",
    "pending_f1 = timesheet_df[(timesheet_df['START_TIME']>f1_2025_last_update) & (timesheet_df['START_TIME']<pd.Timestamp.now())]\n",
    "#pending_f1 = timesheet_df[(timesheet_df['START_TIME']>pd.Timestamp('2025-09-20')) & (timesheet_df['START_TIME']<pd.Timestamp('2025-09-21'))]\n",
    "#map_to_df = dict(zip(df_og['SESSION'].unique(), timesheet_df['SESSION'].unique()))\n",
    "map_to_df = {'1': 'Practice 1', '2': 'Practice 2', '3': 'Practice 3',\n",
    " 'qualifying': 'Qualifying', 'race-result': 'Race',\n",
    " 'sprint-qualifying': 'Sprint Qualifying', 'sprint-results': 'Sprint'}\n",
    "if not refresh_all and os.path.exists('data-cache/f1_2025.pqt'):\n",
    "    df_og = pd.read_parquet('data-cache/f1_2025.pqt')\n",
    "if len(pending_f1)==0 and os.path.exists('data-cache/f1_2025.pqt'):\n",
    "    df = df_og.copy()\n",
    "    df['RACE_NUM'] = df['RACE'].map(dict((v,k) for k,v in enumerate(df['RACE'].unique(), start=1)))\n",
    "    del df_og\n",
    "else:\n",
    "    if not os.path.exists('data-cache/f1_2025.pqt'):\n",
    "        df_og = pd.DataFrame(columns=['YEAR', 'RACE'])\n",
    "    for race in race_cards:\n",
    "        event_url = base_url+race['href']\n",
    "        url_name = event_url.split('/')[-1]\n",
    "        if not refresh_all and not url_name in pending_f1['RACE'].unique():\n",
    "            continue\n",
    "        else:\n",
    "            year = event_url.split('/')[-2]\n",
    "            event_links_soup = extract_text_from_dynamic_site(base_url+race['href'], wait_time=1)\n",
    "            results_links = event_links_soup.find_all('a', string='Results')\n",
    "            for session_a in results_links:\n",
    "                session_url = session_a['href']\n",
    "                session_name = session_url.split('/')[-1]\n",
    "                session_soup = extract_text_from_dynamic_site(base_url+session_url, wait_time=1)\n",
    "                try:\n",
    "                    session_df = pd.read_html(StringIO(session_soup.find_all('table')[0].prettify()))[0]\n",
    "                    og_cols = list(session_df.columns)\n",
    "                    session_df['YEAR'] = year\n",
    "                    session_df['RACE'] = url_name\n",
    "                    session_df['SESSION'] = session_name\n",
    "                    session_df = session_df[['YEAR', 'RACE', 'SESSION']+og_cols]\n",
    "                    session_df = session_df[~session_df['DRIVER'].str.contains('Note')]\n",
    "                    dfs.append(session_df)\n",
    "                    print(year, url_name, session_name)\n",
    "                except Exception as e:\n",
    "                    print(year, url_name, session_name, e)\n",
    "    df_og = df_og.set_index(['YEAR', 'RACE'])\n",
    "    df_extra = pd.concat(dfs).reset_index(drop=True).set_index(['YEAR', 'RACE'])\n",
    "    df_extra['SESSION'] = df_extra['SESSION'].map(map_to_df)\n",
    "    df = pd.concat([df_og[~df_og.index.isin(df_extra.index)], df_extra]).reset_index()\n",
    "    df['POS.'] = df['POS.'].astype('str')\n",
    "    df['NO.'] = df['NO.'].astype('int')\n",
    "    df['LAPS'] = df['LAPS'].astype('float')\n",
    "    df['PTS.'] = df['PTS.'].astype('float')\n",
    "    df['RACE_NUM'] = df['RACE'].map(dict((v,k) for k,v in enumerate(df['RACE'].unique(), start=1)))\n",
    "    df.to_parquet('data-cache/f1_2025.pqt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab47731a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.sample(5).to_html(index=False)\n",
    "x = x.replace(' border=\"1\" class=\"dataframe\"', '').replace(' style=\"text-align: right;\"', '')\n",
    "x = x.splitlines()\n",
    "y = []\n",
    "for line in x:\n",
    "    if line.strip() != \"\":\n",
    "        y.append(line.strip())\n",
    "x = ''.join(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff92654c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: https://www.formula1.com/en/results/2025/drivers\n"
     ]
    }
   ],
   "source": [
    "# Drivers\n",
    "drivers_last_update = pd.to_datetime(os.path.getmtime('data-cache/drivers_standings.html'), unit='s')\n",
    "drivers_last_update = drivers_last_update + tz_timedelta\n",
    "pending_points = timesheet_df[(timesheet_df['SESSION'].isin(['Sprint', 'Race'])) & (timesheet_df['START_TIME']>drivers_last_update) & (timesheet_df['START_TIME']<pd.Timestamp.now())]\n",
    "if len(pending_points)==0:\n",
    "    # Drivers\n",
    "    with open(\"data-cache/drivers_standings.html\", \"r\") as f:\n",
    "        dr_minified = f.read()\n",
    "url = f\"https://www.formula1.com/en/results/2025/drivers\"\n",
    "soup_og = extract_text_from_dynamic_site(url, wait_time=3)\n",
    "html_table = soup_og.find_all('table')[0]\n",
    "html_text = str(html_table.prettify())\n",
    "html_text = re.sub(\" class=\\\"[^\\\"]*\\\"\", \"\", html_text)\n",
    "html_text = re.sub(\"<img[^>]*>\", \"\", html_text)\n",
    "html_text = re.sub(\"<a[^>]*>\", \"\", html_text)\n",
    "html_text = re.sub(\"<span[^>]*>\", \"\", html_text)\n",
    "html_text = re.sub(\"</span[^>]*>\", \"\", html_text)\n",
    "html_text = re.sub(\"<br>\", \"\", html_text)\n",
    "html_text = re.sub(\"<p>\", \"\", html_text)\n",
    "html_text = re.sub(\"\\\\\\n *\", \"\", html_text)\n",
    "dr_raw_markdown_table = htmltabletomd.convert_table(html_text)\n",
    "drivers = pd.read_html(StringIO(html_text))[0]\n",
    "dr_html_table = drivers.set_index('POS.')[['DRIVER', 'TEAM', 'PTS.']].to_html(border='')\n",
    "dr_minified = htmlmin.minify(dr_html_table, remove_empty_space=True).replace(\" class=dataframe\", \"\").replace(' style=\"text-align: right;\"', \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b422ca68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan], dtype=object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['SESSION'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804a46ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write dr_minified to an html file\n",
    "with open(\"data-cache/drivers_standings.html\", \"w\") as f:\n",
    "    f.write(dr_minified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bec4eca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HTML table whitespace\n",
    "dr_html_table = drivers.set_index('POS.')[['DRIVER', 'TEAM', 'PTS.']].to_html(border='')\n",
    "# Minify HTML\n",
    "dr_minified = htmlmin.minify(dr_html_table, remove_empty_space=True)\n",
    "# Markdown table\n",
    "dr_markdown_table = drivers.set_index('POS.')[['DRIVER', 'TEAM', 'PTS.']].to_markdown()\n",
    "# Natural language - New line\n",
    "dr_nl_1 = []\n",
    "for row in drivers[['POS.', 'DRIVER', 'TEAM', 'PTS.']].values:\n",
    "    dr_nl_1.append(f\"{row[0]}. {row[1]} has {row[3]} points and drives for {row[2]}.\")\n",
    "dr_nl_1 = '\\n'.join(dr_nl_1)\n",
    "# Natural language - <> tag inline\n",
    "dr_nl_2 = []\n",
    "for row in drivers[['POS.', 'DRIVER', 'TEAM', 'PTS.']].values:\n",
    "    dr_nl_2.append(f\"<{row[0]}>{row[1]} has {row[3]} points and drives for {row[2]}</{row[0]}>\")\n",
    "dr_nl_2 = ''.join(dr_nl_2)\n",
    "# Natural language - <> tag new line\n",
    "dr_nl_3 = []\n",
    "for row in drivers[['POS.', 'DRIVER', 'TEAM', 'PTS.']].values:\n",
    "    dr_nl_3.append(f\"<{row[0]}>{row[1]} has {row[3]} points and drives for {row[2]}</{row[0]}>\")\n",
    "dr_nl_3 = '\\n'.join(dr_nl_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e47f19ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "dr_table_formats = {\n",
    "    \"html_table\": dr_html_table,\n",
    "    \"html_mini\": dr_minified,\n",
    "    \"markdown_table\": dr_markdown_table,\n",
    "    \"raw_markdown_table\": dr_raw_markdown_table,\n",
    "    \"natural_language_new_line\": dr_nl_1,\n",
    "    \"natural_language_inline_tags\": dr_nl_2,\n",
    "    \"natural_language_new_line_tags\": dr_nl_3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d67e31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: https://www.formula1.com/en/results/2025/team\n"
     ]
    }
   ],
   "source": [
    "# Teams\n",
    "teams_last_update = pd.to_datetime(os.path.getmtime('data-cache/team_standings.html'), unit='s')\n",
    "teams_last_update = teams_last_update + tz_timedelta\n",
    "pending_points = timesheet_df[(timesheet_df['SESSION'].isin(['Sprint', 'Race'])) & (timesheet_df['START_TIME']>teams_last_update) & (timesheet_df['START_TIME']<pd.Timestamp.now())]\n",
    "if len(pending_points)==0:\n",
    "    with open(\"data-cache/team_standings.html\", \"r\") as f:\n",
    "        tm_minified = f.read()\n",
    "url = f\"https://www.formula1.com/en/results/2025/team\"\n",
    "soup_og = extract_text_from_dynamic_site(url, wait_time=3)\n",
    "html_table = soup_og.find_all('table')[0]\n",
    "html_text = str(html_table.prettify())\n",
    "html_text = re.sub(\" class=\\\"[^\\\"]*\\\"\", \"\", html_text)\n",
    "html_text = re.sub(\"<img[^>]*>\", \"\", html_text)\n",
    "html_text = re.sub(\"<a[^>]*>\", \"\", html_text)\n",
    "html_text = re.sub(\"<span[^>]*>\", \"\", html_text)\n",
    "html_text = re.sub(\"</span[^>]*>\", \"\", html_text)\n",
    "html_text = re.sub(\"<br>\", \"\", html_text)\n",
    "html_text = re.sub(\"<p>\", \"\", html_text)\n",
    "html_text = re.sub(\"\\\\\\n *\", \"\", html_text)\n",
    "tm_raw_markdown_table = htmltabletomd.convert_table(html_text)\n",
    "teams = pd.read_html(StringIO(html_text))[0]\n",
    "# HTML table whitespace\n",
    "tm_html_table = teams.set_index('POS.')[['TEAM', 'PTS.']].to_html(border='')\n",
    "# Minify HTML\n",
    "tm_minified = htmlmin.minify(tm_html_table, remove_empty_space=True).replace(\" class=dataframe\", \"\").replace(' style=\"text-align: right;\"', \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1d62c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write dr_minified to an html file\n",
    "with open(\"data-cache/team_standings.html\", \"w\") as f:\n",
    "    f.write(tm_minified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "872f50cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HTML table whitespace\n",
    "tm_html_table = teams.set_index('POS.')[['TEAM', 'PTS.']].to_html(border='')\n",
    "# Minify HTML\n",
    "tm_minified = htmlmin.minify(tm_html_table, remove_empty_space=True)\n",
    "# Markdown table\n",
    "tm_markdown_table = teams.set_index('POS.')[['TEAM', 'PTS.']].to_markdown()\n",
    "# Natural language - New line\n",
    "tm_nl_1 = []\n",
    "for row in teams[['POS.', 'TEAM', 'PTS.']].values:\n",
    "    tm_nl_1.append(f\"{row[0]}. {row[1]} has {row[2]} points.\")\n",
    "tm_nl_1 = '\\n'.join(tm_nl_1)\n",
    "# Natural language - <> tag inline\n",
    "tm_nl_2 = []\n",
    "for row in teams[['POS.', 'TEAM', 'PTS.']].values:\n",
    "    tm_nl_2.append(f\"<{row[0]}>{row[1]} has {row[2]} points</{row[0]}>\")\n",
    "tm_nl_2 = ''.join(tm_nl_2)\n",
    "# Natural language - <> tag new line\n",
    "tm_nl_3 = []\n",
    "for row in teams[['POS.', 'TEAM', 'PTS.']].values:\n",
    "    tm_nl_3.append(f\"<{row[0]}>{row[1]} has {row[2]} points</{row[0]}>\")\n",
    "tm_nl_3 = '\\n'.join(tm_nl_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "388587bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tm_table_formats = {\n",
    "    \"html_table\": tm_html_table,\n",
    "    \"html_mini\": tm_minified,\n",
    "    \"markdown_table\": tm_markdown_table,\n",
    "    \"raw_markdown_table\": tm_raw_markdown_table,\n",
    "    \"natural_language_new_line\": tm_nl_1,\n",
    "    \"natural_language_inline_tags\": tm_nl_2,\n",
    "    \"natural_language_new_line_tags\": tm_nl_3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ab1989",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_formats = list(set(dr_table_formats.keys()).intersection(set(tm_table_formats.keys())))\n",
    "qas = pd.read_csv('test_prompts.txt', sep='|', header=None, names=['Prompt', 'Answer']).values\n",
    "curr_date = pd.Timestamp.now().strftime('%b %d, %Y')\n",
    "table_formats = ['html_table',\n",
    " 'html_mini',\n",
    " 'raw_markdown_table',\n",
    " 'markdown_table']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d4eae9",
   "metadata": {},
   "source": [
    "### Results lookup\n",
    "- Select race number, race location, driver, positions\n",
    "- Query: Who was first in imola?\n",
    "- API: positions=[1], races=['imola'], drivers=None, race_numbers=None\n",
    "- Query: What are the last 3 results from Oscar Piastri?\n",
    "- API: positions=None, races=[-3:], drivers=['Oscar Piastri']\n",
    "\n",
    "#### Steps:\n",
    "1. Automate extraction from web to local DB\n",
    "2. Create sql-like syntax for extracting to local DB\n",
    "3. Maintain local DB cache"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7eaa4a",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "82db198b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/13 - markdown_tableable\r"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for i, (prompt, answer) in enumerate(qas[:3]):\n",
    "    for curr_table_name in table_formats:\n",
    "        # Point to the local server\n",
    "        client = OpenAI(base_url=\"http://localhost:1234/v1\", api_key=\"lm-studio\")\n",
    "        model = \"qwen/qwen3-4b-2507\"\n",
    "        def get_f1_driver_standings() -> str:\n",
    "            \"\"\"Get the current F1 drivers standings. \n",
    "            Use it to determine the points for each driver in the driver's championship.\"\"\"\n",
    "            return dr_table_formats[curr_table_name]\n",
    "        def get_f1_team_standings() -> str:\n",
    "            \"\"\"Get the current F1 teams standings. \n",
    "            Use it to determine the points for each team in the teams' championship.\"\"\"\n",
    "            return tm_table_formats[curr_table_name]\n",
    "\n",
    "        tools = [\n",
    "            {\n",
    "                \"type\":\"function\",\n",
    "                \"function\": {\n",
    "                    \"name\": \"get_f1_driver_standings\",\n",
    "                    \"description\": \"Get the current F1 drivers standings. Use it to determine the points for each driver in the driver's championship.\",\n",
    "                    \"parameters\":  {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {}\n",
    "                    },\n",
    "                        \"additionalProperties\": False,\n",
    "                    },\n",
    "                },\n",
    "            {\n",
    "                \"type\":\"function\",\n",
    "                \"function\": {\n",
    "                    \"name\": \"get_f1_team_standings\",\n",
    "                    \"description\": \"Get the current F1 team standings. Use it to determine the points for each team in the teams' championship.\",\n",
    "                    \"parameters\":  {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {}\n",
    "                    },\n",
    "                        \"additionalProperties\": False,\n",
    "                    },\n",
    "                },\n",
    "        ]\n",
    "\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\":\"system\",\n",
    "                \"content\":f\"\"\"You are an expert in Formula 1 that will assist the user with questions regarding the sport.\n",
    "There are 24 races in the current season and the schedule is as follows:\n",
    "{schedule_text}\n",
    "The current date is {curr_date}. Consider this date when asked about the next race (closest date after the current date) or the previous race (closest date before the current date).\n",
    "There have been a few changes in terms of driver line-ups.\n",
    "If you need to know which driver belongs to a certain team or which team a driver belongs to, use `get_f1_driver_standings`.\n",
    "Use `get_f1_driver_standings` and `get_f1_team_standings` to assist the user.\"\"\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt,\n",
    "            },\n",
    "        ]\n",
    "\n",
    "        # LM Studio\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            tools=tools,\n",
    "        )\n",
    "        first_response = response\n",
    "        # Extract the arguments for get_delivery_date\n",
    "        # Note this code assumes we have already determined that the model generated a function call.\n",
    "        tool_calls = getattr(response.choices[0].message, \"tool_calls\", None)\n",
    "        if tool_calls and len(tool_calls) > 0:\n",
    "            tool_call_response_payloads = []\n",
    "            function_call_results = {}\n",
    "            for tool_call in tool_calls:\n",
    "                # Get a reference to the current module\n",
    "                current_module = sys.modules[__name__]\n",
    "                # Dynamically get and call the function\n",
    "                function_name = tool_call.function.name\n",
    "                result = getattr(current_module, function_name)()\n",
    "                tool_call_response_payload = {\n",
    "                    \"id\":tool_call.id,\n",
    "                    \"type\":tool_call.type,\n",
    "                    \"function\":tool_call.function,\n",
    "                }\n",
    "                tool_call_response_payloads.append(tool_call_response_payload)\n",
    "                function_call_results[function_name] = result\n",
    "            assistant_tool_call_request_message = {\n",
    "                \"role\": \"assistant\",\n",
    "                \"tool_calls\": tool_call_response_payloads\n",
    "            }\n",
    "\n",
    "            # Create a message containing the result of the function call\n",
    "            function_call_result_message = {\n",
    "                \"role\":\"tool\",\n",
    "                \"content\": json.dumps(\n",
    "                    function_call_results\n",
    "                ),\n",
    "                \"tool_call_id\": tool_call.id,\n",
    "            }\n",
    "\n",
    "            # Prepare the chat completion call payload\n",
    "            completion_messages_payload = [\n",
    "                messages[0],\n",
    "                messages[1],\n",
    "                assistant_tool_call_request_message,\n",
    "                function_call_result_message,\n",
    "            ]\n",
    "\n",
    "            # Call the OpenAI API's chat completions endpoint to send the tool call result back\n",
    "            # to the model\n",
    "            response = client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=completion_messages_payload,\n",
    "            )\n",
    "\n",
    "        final_response = response.choices[0].message.content\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\":\"system\",\n",
    "                \"content\":\"You a teacher evaluating student answers to questions about Formula 1. You have a <question> a <correct_answer> and a <student_answer>. Only respond with 'Correct' or 'Incorrect'.\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"<question>{prompt}</question><correct_answer>{answer}</correct_answer><student_answer>{final_response}</student_answer>\",\n",
    "            },\n",
    "        ]\n",
    "\n",
    "        # LM Studio\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "        )\n",
    "        evaluation = response.choices[0].message.content\n",
    "        results.append([model, curr_table_name, prompt, answer, final_response, len(final_response), evaluation])\n",
    "        print(f\"{i+1}/{len(qas)} - {curr_table_name}\", end='\\r')\n",
    "results_df = pd.DataFrame(results, columns=['model', 'table_format', 'prompt', 'correct_answer', 'final_answer', 'final_answer_length', 'evaluation'])\n",
    "results_df['good'] = results_df['evaluation'].map({'Correct': 1, 'Incorrect': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4d395747",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>table_format</th>\n",
       "      <th>good</th>\n",
       "      <th>final_answer_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>html_mini</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>122.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>html_table</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>168.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>markdown_table</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>122.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>raw_markdown_table</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>158.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         table_format      good  final_answer_length\n",
       "0           html_mini  0.666667           122.000000\n",
       "1          html_table  0.666667           168.333333\n",
       "2      markdown_table  0.666667           122.666667\n",
       "3  raw_markdown_table  0.666667           158.333333"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.groupby('table_format')[['good', 'final_answer_length']].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "acdb01f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>good</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the next race?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>When is the Mexican grand prix?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>What is the last race on the calendar?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   prompt  good\n",
       "1                  What is the next race?     1\n",
       "5         When is the Mexican grand prix?     1\n",
       "9  What is the last race on the calendar?     0"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df[results_df['table_format']=='html_mini'][['prompt', 'good']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a4c90099",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>good</th>\n",
       "      <th>final_answer_length</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prompt</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>What is the last race on the calendar?</th>\n",
       "      <td>0.0</td>\n",
       "      <td>107.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>What is the next race?</th>\n",
       "      <td>1.0</td>\n",
       "      <td>268.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>When is the Mexican grand prix?</th>\n",
       "      <td>1.0</td>\n",
       "      <td>53.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        good  final_answer_length\n",
       "prompt                                                           \n",
       "What is the last race on the calendar?   0.0                107.0\n",
       "What is the next race?                   1.0                268.5\n",
       "When is the Mexican grand prix?          1.0                 53.0"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.groupby('prompt')[['good', 'final_answer_length']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fba58395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "html_table\n",
      "['What is the last race on the calendar?'\n",
      " 'Abu Dhabi Grand Prix on 5 to 7 December']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The last race on the calendar is the Abu Dhabi Grand Prix, which takes place from 5th to 7th December 2025."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tf = 0\n",
    "pmpt = 2\n",
    "print(table_formats[tf])\n",
    "print(qas[pmpt])\n",
    "display(Markdown(results_df[(results_df['table_format']==table_formats[tf]) & (results_df['prompt']==qas[pmpt][0])]['final_answer'].iloc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8556c431",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df[(results_df['table_format']==table_formats[tf])].groupby('prompt')[['good', 'final_answer_length']].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502ec28c",
   "metadata": {},
   "source": [
    "# TODO\n",
    "- Improve caching by using race schedule\n",
    "- Test different schedule formats\n",
    "- Add result lookup functions\n",
    "- Fix last race and current race eval"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
